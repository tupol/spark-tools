# SimpleFileStreamingSqlProcessor Example
#
# Apply the SimpleFileStreamingSqlProcessor to a single file, using an inline SQL and variables
#
SimpleFileStreamingSqlProcessor: {
  # Input configuration: tables descriptions, variables and the query to be ran
  input: {
    # It contains a map of table names that need to be associated with the files
    # Please keep in mind that for local resources the path needs to be relative to the sql-processor.sh script file
    tables {
      "table1": {
        path: "/out/in-example-1"
        format: "json"
        schema: {
          "type" : "struct",
          "fields" : [ {
            "name" : "id",
            "type" : "string",
            "nullable" : true,
            "metadata" : { }
          }, {
            "name" : "timestamp",
            "type" : "string",
            "nullable" : true,
            "metadata" : { }
          }, {
            "name" : "order",
            "type" : "string",
            "nullable" : true,
            "metadata" : { }
          } ]
        }
      }
    }
    variables {
      columns: "*"
      filter_id: "1001"
    }
    # The query that will be applied on the input tables
    # The query must be written on a single line.
    # All quotes must be escaped.
    sql.line: "SELECT {{columns}} FROM table1 WHERE table1.id='{{filter_id}}'"
  }
  output: {
    # The path where the results will be saved
    path: "/out/out-example-1"
    # The format of the output file; acceptable values are "json", "avro", "json" and "parquet"
    format: "json"
    # Output mode: append, overwrite,...
    outputMode: "append"
    # The output partition columns
    partition.columns: ["id", "timestamp"]
    checkpointLocation: "/out/checkpoints/out-example-1-cp"
    trigger {
      # once, Continuous or ProcessingTime
      type: Continuous
      interval: 0
    }
  }
}
