# SimpleFileStreamingSqlProcessor Example
#
# Apply the SimpleFileStreamingSqlProcessor to a single file using a more complex input parsing setup
#
SimpleFileStreamingSqlProcessor: {
  # Input configuration: tables descriptions, variables and the query to be ran
  input: {
    # It contains a map of table names that need to be associated with the files
    # Please keep in mind that for local resources the path needs to be relative to the sql-processor.sh script file
    tables {
      "table1": {
        path: "/out/in-example-2"
        format: "csv"
        schema: {
          "type" : "struct",
          "fields" : [ {
            "name" : "id",
            "type" : "string",
            "nullable" : true,
            "metadata" : { }
          }, {
            "name" : "timestamp",
            "type" : "string",
            "nullable" : true,
            "metadata" : { }
          }, {
            "name" : "address",
            "type" : "string",
            "nullable" : true,
            "metadata" : { }
          } ]
        }
      }
    }
    variables {
      columns: "*"
      filter_id: "1001"
    }
    # The query that will be applied on the input tables
    # The query must be written on a single line.
    # All quotes must be escaped.
    sql.line: "SELECT * FROM table1 "
  }
  output: {
    # The format of the output file; acceptable values are "json", "avro", "json" and "parquet"
    format: "json"
    # The path where the results will be saved
    path: "/out/out-example-2"
    checkpointLocation: "/out/checkpoints/out-example-2-cp"
    outputMode: append
    trigger {
      # once, continuous or processing-time
      type: processing-time
      interval: 2s
    }
    # The output partition columns
    partition.columns: ["id"]
  }
}
